<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
	
	<meta name="description" content="Adventures in AI: Concepts & Language Models (2023)">
	<meta name="author" content="Thushan Fernando">

	<title>Adventures in AI: Concepts & Language Models (2023)</title>
	<link rel="stylesheet" href="engine/reset.css">
	<link rel="stylesheet" href="engine/reveal.css">
	<link rel="stylesheet" href="engine/theme/sixpivot.css" id="theme">
	<link rel="stylesheet" href="engine/plugin/highlight/monokai.css" id="highlight-theme">
	<link rel="stylesheet" href="engine/2shan.css">
</head>
<body>
	<div class="reveal">
		<div class="slides">
			<section data-markdown>
				## Adventures in AI
				## Concepts & Language Models
				Thushan Fernando

				![ChatGPT Enthusiast](assets/img/memes/chatgpt-enthusiast.jpg)

				[@thushanfernando](https://twitter.com/thushanfernando)

				[github.com/thushan](https://github.com/thushan)
			</section>

			<section>
				<section>
					<h2>Modern AI Evolution: 2022</h2>
					<table class="timeline">
						<tr class="fragment">
							<th>Feb, 2022</th>
							<td>DeepMind - Alpha Code</td>
						</tr>
						<tr class="fragment">
							<th>Apr, 2022</th>
							<td><span class="star"></span>OpenAI: Dall-E 2, Google PaLM (540B)</td>
						</tr>
						<tr class="fragment">
							<th>May, 2022</th>
							<td>Google Imagen AI</td>
						</tr>
						<tr class="fragment">
							<th>June, 2022</th>
							<td><span class="star"></span>Github CoPilot</td>
						</tr>
						<tr class="fragment">
							<th>July, 2022</th>
							<td><span class="star"></span>Stability AI: Stability Diffusion</td>
						</tr class="fragment">
						<tr class="fragment">
							<th>Sept, 2022</th>
							<td><span class="star"></span>OpenAI: Whisper, Meta: Make a Video</td>
						</tr>
						<tr class="fragment">
							<th>Oct, 2022</th>
							<td>LangChain on Github</td>
						</tr>
						<tr class="fragment">
							<th>Nov, 2022</th>
							<td><span class="mind-blown"></span>OpenAI: ChatGPT</td>
						</tr>
					</table>
				</section>
				<section>
					<h2>Modern AI Evolution: 2023</h2>
					<table class="timeline">
						<tr class="fragment">
							<th>Feb, 2023</th>
							<td>Meta: LLaMA (7-65B)</td>
						</tr>
						<tr class="fragment">
							<th>Mar, 2023</th>
							<td><span class="mind-blown"></span>OpenAI: ChatGPT4, Stanford: Alpaca (13B)</td>
						</tr>
						<tr class="fragment">
							<th>Apr, 2023</th>
							<td>UC Berkley: Vicuna (13B)</td>
						</tr>
						<tr class="fragment">
							<th>May, 2023</th>
							<td>Google: PaLM 2</td>
						</tr>
						<tr class="fragment">
							<th>June, 2023</th>
							<td><span class="mind-blown"></span>Microsoft: Orca LLM, OpenLLaMA (13B)</td>
						</tr>
					</table>
				</section>
			</section>
			<section>
				<section>
					<h2>What's this all about then ey?</h2>
					<img class="fragment" src="assets/img/memes/its-all-llm.jpeg" />
				</section>
				<section>
					<h2>Language models</h2>
					<img src="assets/img/text-to-llm-to-output.png" class="fragment" />
					<ul>
						<li class="fragment">Using Deep Learning, determine next-word probability analysing text data.</li>
						<li class="fragment">Algorithms train model based on linguistic rules for context in natural language.</li>
						<li class="fragment">Models use this to predict new sentences.</li>
					</ul>
				</section>
				<section>
					<h2>There are different types...</h2>
					<ul>
						<li class="fragment">
							Traditional statistical (probabilty distribution) modeling:
							<p>N-Gram, Unigram, Bidirectional (ML), Expotential, Neural Language (NN)</p>
						</li>
						<li class="fragment">
							We used N-Gram in the early days, but most are Neural Language based now.
						</li>
					</ul>
				</section>
				<section>
					<h2>N-Gram recap</h2>
					<img src="assets/diagrams/ngram-examples.svg" class="fragment" />
				</section>
				<section>
					<h2>Neural Network Based Models</h2>
					<p>Use NN to predict probability of next word in a sequence.</p>
					<p class="fragment">Captures complex linguistic structures, words & context.</p>
					<ul>
						<li class="fragment"><em>Large Language Models</em> (aka Generative AI Models) <br/> <span class="examples">Eg. GPT-4, GPT-3.5, BERT, RoBERTa, BLOOM, Claude</span></li>
						<li class="fragment"><em>Fine Tuned Models</em> - Smaller training set for a specific task. <br/><span class="examples">Eg. Sentiment Analysis, Summarisation, Named Entity Recognition (NER)</span></li>
						<li class="fragment"><em>Edge Models</em> - Tiny, ideal for mobile/IoT devices, no cloud.<br/><span class="examples">Eg. Google Translate, Tensorflow Lite, Pytorch Mobile</span></li>
					</ul>
					<p class="fragment">Unfortunately, most use ChatGPT for all the things right now.</p>
				</section>
				<section>
					<h2>They vary in size...</h2>
					<p class="fragment">We measure size in the <em class="heavy">number of parameters</em>.</p>
					<ul>
						<li class="fragment"><em>Large Language Models</em> - Gigabytes, some like GPT4 could be Petabytes. <br/> <span class="examples">Eg. GPT-4, GPT-3.5, BERT, RoBERTa, BLOOM, Claude</span></li>
						<li class="fragment"><em>Fine Tuned Models</em> -  <br/><span class="examples">Eg. Sentiment Analysis, Summarisation, Named Entity Recognition (NER)</span></li>
						<li class="fragment"><em>Edge Models</em> - <br/><span class="examples">Eg. Google Translate, Tensorflow Lite, Pytorch Mobile</span></li>
					</ul>
					<p class="fragment">But the physical size is still important for certain platforms.</p>
				</section>
				<section>
					<h2>Under the hood...</h2>
					<img class="fragment" src="assets/img/memes/transformer-transforms.gif"/>
					<p class="fragment">Language models utilise a <em class="light">transformer model</em>.</p>
					<p class="fragment">via Vaswani et al. paper, <a href="https://arxiv.org/abs/1706.03762">'Attention is All You Need'</a> in 2017.</p>					
				</section>
				<section>
					<h2>Transformer Models</h2>					
					<p class="fragment">Is the break-through for 'modern AI' as we know it.</p>
					<p class="fragment">Concept of 'Attention' to understand important words & its relationships.</p>
					<p class="fragment">Tokenise input to a sequence of words, encode words to numbers & convert into <em class="dark">embeddings</em>.</p>
				</section>
				<section>
					<h2>An Embeddings example...</h2>					
					<blockquote class="fragment smaller">
As she said this, she looked down at her hands, and was surprised to find that she had put on one of the rabbit's little gloves while she was talking. 
</blockquote>
					<pre class="fragment">
['As', ' she', ' said', ' this', ',', ' she', ' looked', ' down', ' at', 
' her', ' hands', ',', ' and', ' was', ' surprised', ' to', ' find', 
' that', ' she', 'had', ' put', ' on', ' one', ' of', ' the', ' rabbit', 
"'s", ' little', ' gloves', ' while', ' she', ' was', ' talking', '.']
					</pre>
					<pre class="fragment">
[ 2.49 0.22 -0.36 -1.55 0.22 -2.45 2.65 -1.6 -0.14 2.26
...
-1.26 -0.61 -0.61 -1.89 -1.87 -0.16 3.34 -2.67 0.42 -1.71 ]
					</pre>
				</section>
			</section>
			</section>
			<section>
				<section>
					<h2>Some Key Concepts</h2>						
				</section>
				<section>
					<p>Machine learning model that can learn, understand &  process linguistics efficiently.</p>
				</section>
			</section>
			<section>
				<section>
					<h2>Learning Resouces</h2>
					<ul class="resources">
						<li><a href="https://www.cloudskillsboost.google/course_templates/536">Introduction to Generative AI</a> - Google, 1d</li>
						<li><a href="https://huggingface.co/learn/nlp-course/chapter1/1">Hugging Face Courseware</a> - for NLP via Hugging Face</li>
					</ul>
				</section>
				<section>
					<h2>Interesting Papers</h2>
					<ul class="resources">
						<li class="star"><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> (2017)</li>
						<li><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a> (2019)</li>
						<li><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a> (2018)</li>
						<li><a href="https://arxiv.org/abs/2304.00612">Eight Things to Know about Large Language Models</a> (2023)</li>
						<li class="mind-blown"><a href="https://arxiv.org/pdf/2306.02707.pdf">Orca: Progressive Learning from Complex Explanation Traces of GPT-4</a> (2023)</li>
					</ul>
				</section>
			</section>
		</div>
	</div>

	<script src="engine/reveal.js"></script>
	<script src="engine/plugin/chart/chart.min.js"></script>
	<script src="engine/plugin/chart/plugin.js"></script>
	<script src="engine/plugin/chalkboard/plugin.js"></script>
	<script src="engine/plugin/notes/notes.js"></script>
	<script src="engine/plugin/markdown/markdown.js"></script>
	<script src="engine/plugin/highlight/highlight.js"></script>
	<script>
		Reveal.initialize({
			hash: true,
			chart: {
				defaults: {
					global: {
						title: { fontColor: "#FFF" },
						legend: {
							labels: { fontColor: "#FFF" },
						},
					},
					scale: {
						scaleLabel: { fontColor: "#FFF" },
						gridLines: { color: "#FFF", zeroLineColor: "#FFF" },
						ticks: { fontColor: "#FFF" },
					}
				},
				line: { borderColor: ["rgba(20,220,220,.8)", "rgba(220,120,120,.8)", "rgba(20,120,220,.8)"], "borderDash": [[5, 10], [0, 0]] },
				bar: { backgroundColor: ["rgba(20,220,220,.8)", "rgba(220,120,120,.8)", "rgba(20,120,220,.8)"] },
				pie: { backgroundColor: [["rgba(0,0,0,.8)", "rgba(220,20,20,.8)", "rgba(20,220,20,.8)", "rgba(220,220,20,.8)", "rgba(20,20,220,.8)"]] },
				radar: { borderColor: ["rgba(20,220,220,.8)", "rgba(220,120,120,.8)", "rgba(20,120,220,.8)"] },
			},
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealChart, RevealChalkboard]
		});
	</script>
</body>

</html>